{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "from IPython import display\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from scipy.misc import imread\n",
    "import math\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),])),\n",
    "        batch_size=128, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])\n",
    "                       ),\n",
    "        batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simple test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),])),\n",
    "        batch_size=128, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=False, transform=transforms.Compose([transforms.ToTensor(),])\n",
    "                       ),\n",
    "        batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 1024)\n",
    "        self.out = nn.Linear(1024, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        output = self.fc1(x)\n",
    "        output = F.relu(output)\n",
    "        output = self.out(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "from pyro.distributions import Normal, Categorical\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "import pyro.poutine as poutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_normal_prior(name, params):\n",
    "    mu_param = pyro.param('{}_mu'.format(name), torch.zeros_like(params))\n",
    "    sigma_param = F.softplus(pyro.param(\"{}_sigma\".format(name), torch.ones_like(params)))\n",
    "    prior = Normal(loc=mu_param, scale=sigma_param)\n",
    "    return prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_softmax = nn.LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    fc1w_prior = Normal(loc=torch.zeros_like(net.fc1.weight), scale=torch.ones_like(net.fc1.weight))\n",
    "    fc1b_prior = Normal(loc=torch.zeros_like(net.fc1.bias), scale=torch.ones_like(net.fc1.bias))\n",
    "    \n",
    "    outw_prior = Normal(loc=torch.zeros_like(net.out.weight), scale=torch.ones_like(net.out.weight))\n",
    "    outb_prior = Normal(loc=torch.zeros_like(net.out.bias), scale=torch.ones_like(net.out.bias))\n",
    "\n",
    "    priors = {\n",
    "        'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,\n",
    "        'out.weight': outw_prior, 'out.bias': outb_prior\n",
    "    }\n",
    "\n",
    "    # lift module parameters to random variables sampled from the priors\n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "\n",
    "    # sample a classifier\n",
    "    lifted_reg_model = lifted_module()\n",
    "\n",
    "    p_hat = log_softmax(lifted_reg_model(x_data))\n",
    "\n",
    "    pyro.sample(\"obs\", Categorical(logits=p_hat), obs=y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(x_data, y_data):\n",
    "    # fc1 weight distribution priors\n",
    "    fc1w_prior = dense_normal_prior('fc1w', net.fc1.weight)\n",
    "    # fc1 bias distribution priors\n",
    "    fc1b_prior = dense_normal_prior('fc1b', net.fc1.bias)\n",
    "\n",
    "    # fc3 weight distribution priors\n",
    "    outw_prior = dense_normal_prior('outw', net.out.weight)\n",
    "    # fc3 bias distribution priors\n",
    "    outb_prior = dense_normal_prior('outb', net.out.bias)\n",
    "\n",
    "    priors = {\n",
    "        'fc1.weight': fc1w_prior, 'fc1.bias': fc1b_prior,\n",
    "        'out.weight': outw_prior, 'out.bias': outb_prior\n",
    "    }\n",
    "\n",
    "    lifted_module = pyro.random_module(\"module\", net, priors)\n",
    "    return lifted_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (fc1): Linear(in_features=784, out_features=1024, bias=True)\n",
       "  (out): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = Adam({\"lr\": 0.01})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T):\n",
    "    sampled_models = [guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = torch.stack(yhats, dim=1)\n",
    "    mean = torch.mean(yhats, 1)\n",
    "    return np.argmax(mean.cpu().numpy(), axis=1)\n",
    "\n",
    "def evaluate(T, loader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted = predict(images.view(images.size(0), -1).cuda(), T=T)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == np.array(labels)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  0  Loss  84.36735980621974 Accuracy  89.03\n",
      "Epoch  1  Loss  84.09832319690386 Accuracy  89.72\n",
      "Epoch  2  Loss  84.27995190889041 Accuracy  89.55\n",
      "Epoch  3  Loss  84.30779006101291 Accuracy  89.27\n",
      "Epoch  4  Loss  83.8069900431792 Accuracy  89.02\n",
      "Epoch  5  Loss  84.53469102640152 Accuracy  89.36\n",
      "Epoch  6  Loss  83.8996834798336 Accuracy  89.05\n",
      "Epoch  7  Loss  83.92807042242686 Accuracy  89.59\n",
      "Epoch  8  Loss  84.11383662295341 Accuracy  89.61\n",
      "Epoch  9  Loss  84.39601743836403 Accuracy  89.37\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 10\n",
    "loss = 0\n",
    "\n",
    "for j in range(num_iterations):\n",
    "    loss = 0\n",
    "    for batch_id, data in enumerate(train_loader):\n",
    "        # calculate the loss and take a gradient step\n",
    "        loss += svi.step(data[0].view(data[0].size(0), -1).cuda(), data[1].cuda())\n",
    "    normalizer_train = len(train_loader.dataset)\n",
    "    total_epoch_loss_train = loss / normalizer_train\n",
    "    acc = evaluate(10, test_loader)\n",
    "    print(\"Epoch \", j, \" Loss \", total_epoch_loss_train, 'Accuracy ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy remove samples with all probability less than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T):\n",
    "    sampled_models = [guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = F.softmax(torch.stack(yhats, dim=1), dim=2)\n",
    "    mean = torch.mean(yhats, 1)\n",
    "    return np.argmax(mean.cpu().numpy(), axis=1), mean.cpu().numpy()\n",
    "\n",
    "def evaluate(T, loader, threshold=0.2):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_cnt = 0\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted, mean_prob = predict(images.view(images.size(0), -1).cuda(), T=T)\n",
    "        confidence = np.max(mean_prob, axis=1)\n",
    "        idx = [idx for idx in range(confidence.shape[0]) if confidence[idx]>threshold]\n",
    "        all_cnt += len(labels)\n",
    "        total += len(idx)\n",
    "        correct += (predicted[idx] == np.array(labels)[idx]).sum().item()\n",
    "    return (100 * correct / total), all_cnt-total, total/all_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  93.11460774467136\n",
      "number of samples skipped : 1039\n",
      "raio (able to predict/all sample): 0.8961\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio = evaluate(10, test_loader, threshold=0.5)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  93.81741354386745\n",
      "number of samples skipped : 1007\n",
      "raio (able to predict/all sample): 0.8993\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio = evaluate(20, test_loader, threshold=0.5)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  95.27710843373494\n",
      "number of samples skipped : 1700\n",
      "raio (able to predict/all sample): 0.83\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio = evaluate(10, test_loader, threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  96.42380894653897\n",
      "number of samples skipped : 1751\n",
      "raio (able to predict/all sample): 0.8249\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio = evaluate(20, test_loader, threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T):\n",
    "    sampled_models = [guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = F.softmax(torch.stack(yhats, dim=1), dim=2)\n",
    "    mean = torch.mean(yhats, 1).cpu().numpy()\n",
    "    \n",
    "    # uncertainty\n",
    "    # yhats [batch * 10 * 10]\n",
    "    p_hat = yhats.cpu().numpy()\n",
    "    aleatoric = np.mean(p_hat*(1-p_hat), axis=1) # batch * 10\n",
    "    epistemic = np.mean(p_hat**2, axis=1) - np.mean(p_hat, axis=1)**2 # batch * 10\n",
    "    return np.argmax(mean, axis=1), mean, aleatoric, epistemic\n",
    "\n",
    "def evaluate(T, loader, threshold=0.2):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_cnt = 0\n",
    "    total_alea_thresh = 0\n",
    "    total_epis_thresh = 0\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted, mean_prob, aleatoric, epistemic = predict(images.view(images.size(0), -1).cuda(), T=T)\n",
    "        confidence = np.max(mean_prob, axis=1)\n",
    "        idx = [idx for idx in range(confidence.shape[0]) if confidence[idx]>threshold]\n",
    "        all_cnt += len(labels)\n",
    "        total += len(idx)\n",
    "        correct += (predicted[idx] == np.array(labels)[idx]).sum().item()\n",
    "        \n",
    "        # uncertainty for the best choice\n",
    "        total_alea_thresh += np.choose(predicted, aleatoric.T)[idx].sum().item()\n",
    "        total_epis_thresh += np.choose(predicted, epistemic.T)[idx].sum().item()\n",
    "    return (100 * correct / total), all_cnt-total, total/all_cnt, total_alea_thresh/total, total_epis_thresh/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  93.08652988403212\n",
      "number of samples skipped : 1032\n",
      "raio (able to predict/all sample): 0.83\n",
      "mean epistemic: 0.10166775213885158\n",
      "mean aleaotoric: 0.002358458893843839\n"
     ]
    }
   ],
   "source": [
    "acc, skip, tatio,mean_alea, mean_epis = evaluate(10, test_loader, threshold=0.5)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  93.93265918435382\n",
      "number of samples skipped : 1001\n",
      "raio (able to predict/all sample): 0.83\n",
      "mean epistemic: 0.10918405167539062\n",
      "mean aleaotoric: 0.0023589821815729168\n"
     ]
    }
   ],
   "source": [
    "acc, skip, tatio,mean_alea, mean_epis = evaluate(20, test_loader, threshold=0.5)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  95.39259437944759\n",
      "number of samples skipped : 1709\n",
      "raio (able to predict/all sample): 0.83\n",
      "mean epistemic: 0.09170494259604355\n",
      "mean aleaotoric: 0.00199796977906632\n"
     ]
    }
   ],
   "source": [
    "acc, skip, tatio,mean_alea, mean_epis = evaluate(10, test_loader, threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  96.4006832601269\n",
      "number of samples skipped : 1804\n",
      "raio (able to predict/all sample): 0.83\n",
      "mean epistemic: 0.09480218217685898\n",
      "mean aleaotoric: 0.0020654726052623134\n"
     ]
    }
   ],
   "source": [
    "acc, skip, tatio,mean_alea, mean_epis = evaluate(20, test_loader, threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  96.57275277472863\n",
      "number of samples skipped : 1801\n",
      "raio (able to predict/all sample): 0.83\n",
      "mean epistemic: 0.09811366701405257\n",
      "mean aleaotoric: 0.0020794412326206268\n"
     ]
    }
   ],
   "source": [
    "acc, skip, tatio,mean_alea, mean_epis = evaluate(30, test_loader, threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyse the sample with confidence over 0.6 but prediction is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T):\n",
    "    sampled_models = [guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = F.softmax(torch.stack(yhats, dim=1), dim=2)\n",
    "    mean = torch.mean(yhats, 1).cpu().numpy()\n",
    "    \n",
    "    # uncertainty\n",
    "    # yhats [batch * 10 * 10]\n",
    "    p_hat = yhats.cpu().numpy()\n",
    "    aleatoric = np.mean(p_hat*(1-p_hat), axis=1) # batch * 10\n",
    "    epistemic = np.mean(p_hat**2, axis=1) - np.mean(p_hat, axis=1)**2 # batch * 10\n",
    "    return np.argmax(mean, axis=1), mean, aleatoric, epistemic\n",
    "\n",
    "def evaluate(T, loader, threshold=0.2):\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted, mean_prob, aleatoric, epistemic = predict(images.view(images.size(0), -1).cuda(), T=T)\n",
    "        confidence = np.max(mean_prob, axis=1)\n",
    "        idx = [idx for idx in range(confidence.shape[0]) if confidence[idx]>threshold]\n",
    "        correct = (predicted[idx] == np.array(labels)[idx])\n",
    "        wrong_idx = [i for i in range(len(correct)) if correct[i] == False]\n",
    "        usable_idx = np.array(idx)[wrong_idx]\n",
    "        if len(usable_idx)>0:\n",
    "            return images[usable_idx], labels[usable_idx], mean_prob[usable_idx], aleatoric[usable_idx], epistemic[usable_idx]\n",
    "        else:\n",
    "            return 0, 0, 0, 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label, prob, alea, epis = evaluate(30, test_loader, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence:\n",
      "[1.3061119e-26 1.9618179e-44 1.1713722e-34 3.3333320e-02 1.5227041e-09\n",
      " 7.1329935e-11 0.0000000e+00 3.0022436e-01 6.4332724e-02 6.0210967e-01]\n",
      "label:\n",
      "7\n",
      "prediction\n",
      "9\n",
      "alea \n",
      "[1.3061119e-26 1.9618179e-44 1.1713722e-34 1.5894564e-08 1.5227039e-09\n",
      " 7.1329935e-11 0.0000000e+00 2.2045302e-03 2.1705243e-03 4.3750312e-03]\n",
      "epis\n",
      "[0.0000000e+00 0.0000000e+00 0.0000000e+00 3.2222193e-02 6.7240202e-17\n",
      " 1.4755082e-19 0.0000000e+00 2.0788518e-01 5.8023501e-02 2.3519853e-01]\n"
     ]
    }
   ],
   "source": [
    "num = 1\n",
    "plt.figure()\n",
    "plt.imshow(image[num].numpy().squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('confidence:')\n",
    "print(prob[num])\n",
    "print('label:')\n",
    "print(label[num].numpy())\n",
    "print('prediction')\n",
    "print(np.argmax(prob[num]))\n",
    "print('alea ')\n",
    "print(alea[num])\n",
    "print('epis')\n",
    "print(epis[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Calibration Error (ECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the Expected Calibration Error of a model.\n",
    "    (This isn't necessary for temperature scaling, just a cool metric).\n",
    "    The input to this loss is the logits of a model, NOT the softmax scores.\n",
    "    This divides the confidence outputs into equally-sized interval bins.\n",
    "    In each bin, we compute the confidence gap:\n",
    "    bin_gap = | avg_confidence_in_bin - accuracy_in_bin |\n",
    "    We then return a weighted average of the gaps, based on the number\n",
    "    of samples in each bin\n",
    "    See: Naeini, Mahdi Pakdaman, Gregory F. Cooper, and Milos Hauskrecht.\n",
    "    \"Obtaining Well Calibrated Probabilities Using Bayesian Binning.\" AAAI.\n",
    "    2015.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, softmaxes, labels):\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        ece = torch.zeros(1)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece = ECELoss(n_bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T):\n",
    "    sampled_models = [guide(None, None) for _ in range(T)]\n",
    "    yhats = [F.softmax(model(x).data, dim=1) for model in sampled_models]\n",
    "    yhats = torch.stack(yhats, dim=1)\n",
    "    mean = torch.mean(yhats, 1)\n",
    "    return mean\n",
    "\n",
    "def evaluate(T, loader):\n",
    "    prob_list = []\n",
    "    label_list = []\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted = predict(images.view(images.size(0), -1).cuda(), T=T)\n",
    "        label_list.extend(labels)\n",
    "        prob_list.append(predicted)\n",
    "    label_list = torch.stack(label_list, dim=0).view(-1).cpu()\n",
    "    prob_list = torch.cat(prob_list, dim=0).cpu()  \n",
    "    return ece.forward(prob_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ece_loss: 0.08351756632328033\n"
     ]
    }
   ],
   "source": [
    "ece_loss = evaluate(10, test_loader)\n",
    "print('ece_loss:', str(ece_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliability Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReliabilityDiagram(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the Expected Calibration Error of a model.\n",
    "    (This isn't necessary for temperature scaling, just a cool metric).\n",
    "    The input to this loss is the logits of a model, NOT the softmax scores.\n",
    "    This divides the confidence outputs into equally-sized interval bins.\n",
    "    In each bin, we compute the confidence gap:\n",
    "    bin_gap = | avg_confidence_in_bin - accuracy_in_bin |\n",
    "    We then return a weighted average of the gaps, based on the number\n",
    "    of samples in each bin\n",
    "    See: Naeini, Mahdi Pakdaman, Gregory F. Cooper, and Milos Hauskrecht.\n",
    "    \"Obtaining Well Calibrated Probabilities Using Bayesian Binning.\" AAAI.\n",
    "    2015.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_bins=10):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ReliabilityDiagram, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, softmaxes, labels):\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                x.append(avg_confidence_in_bin)\n",
    "                y.append(accuracy_in_bin)\n",
    "        return torch.stack(x, dim=0).view(-1).cpu().numpy(), torch.stack(y, dim=0).view(-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = ReliabilityDiagram(n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T):\n",
    "    sampled_models = [guide(None, None) for _ in range(T)]\n",
    "    yhats = [F.softmax(model(x).data, dim=1) for model in sampled_models]\n",
    "    yhats = torch.stack(yhats, dim=1)\n",
    "    mean = torch.mean(yhats, 1)\n",
    "    return mean\n",
    "\n",
    "def evaluate(T, loader):\n",
    "    prob_list = []\n",
    "    label_list = []\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted = predict(images.view(images.size(0), -1).cuda(), T=T)\n",
    "        label_list.extend(labels)\n",
    "        prob_list.append(predicted)\n",
    "    label_list = torch.stack(label_list, dim=0).view(-1).cpu()\n",
    "    prob_list = torch.cat(prob_list, dim=0).cpu()  \n",
    "    return label_list, prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, prob = evaluate(10, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = rd(prob, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2        0.2894902  0.3709706  0.4693529  0.5639573  0.66737336\n",
      " 0.7708859  0.87972105 0.9877426 ]\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.2840909  0.36196318 0.50498337 0.7055675  0.8345178\n",
      " 0.92909354 0.97077763 0.99265105]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.bar(x=x, height=y, width=0.05, label='output')\n",
    "plt.plot(np.linspace(0, 1, 11), np.linspace(0, 1, 11), 'r', '--')\n",
    "plt.xlabel('confidence')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Reliability Diagram')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Model Don't Know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST('fashion-mnist-data/', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(),])\n",
    "                       ),\n",
    "        batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict(x, T):\n",
    "    sampled_models = [guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = F.softmax(torch.stack(yhats, dim=1), dim=2)\n",
    "    mean = torch.mean(yhats, 1).cpu().numpy()\n",
    "    \n",
    "    # uncertainty\n",
    "    # yhats [batch * 10 * 10]\n",
    "    p_hat = yhats.cpu().numpy()\n",
    "    aleatoric = np.mean(p_hat*(1-p_hat), axis=1) # batch * 10\n",
    "    epistemic = np.mean(p_hat**2, axis=1) - np.mean(p_hat, axis=1)**2 # batch * 10\n",
    "    return np.argmax(mean, axis=1), mean, aleatoric, epistemic\n",
    "\n",
    "def evaluate(T, loader, threshold=0.2):\n",
    "    entropy = 0\n",
    "    total = 0\n",
    "    all_cnt = 0\n",
    "    total_alea_thresh = 0\n",
    "    total_epis_thresh = 0\n",
    "    entropy = np.array([])\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted, mean_prob, aleatoric, epistemic = predict(images.view(images.size(0), -1).cuda(), T=T)\n",
    "        confidence = np.max(mean_prob, axis=1)\n",
    "        idx = [idx for idx in range(confidence.shape[0]) if confidence[idx]>threshold]\n",
    "        all_cnt += len(labels)\n",
    "        total += len(idx)\n",
    "        entropy = np.concatenate([entropy, confidence])\n",
    "        # uncertainty for the best choice\n",
    "        total_alea_thresh += np.choose(predicted, aleatoric.T).sum().item()\n",
    "        total_epis_thresh += np.choose(predicted, epistemic.T).sum().item()\n",
    "    entropy = -np.log(entropy)\n",
    "    return all_cnt-total, total/all_cnt, total_alea_thresh/total, total_epis_thresh/total, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip, ratio, alea_mean, epis_mean, entropy = evaluate(10, test_loader, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sample skipped  5411\n",
      "predict ratio  0.4589\n",
      "mean alea  0.007267275448067823\n",
      "mean epis  0.45482352414300536\n"
     ]
    }
   ],
   "source": [
    "print('number of sample skipped ', skip)\n",
    "print('predict ratio ',ratio)\n",
    "print('mean alea ', alea_mean)\n",
    "print('mean epis ', epis_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_cnt = pd.Series(entropy).value_counts().sort_index()\n",
    "cumulative = np.cumsum(entropy_cnt.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmcHVWd9/HPl5AFSEjIApqNJGyyhS2AgMjmwjYsIyKrhEEYHRy3kUFHHlQYxxlkVHyJAzwoEcYhKCpPBiPIiAgTFpMIhDUQkkCaAAlJDGQj6fTv+ePU7dx0ujs3IXWruu/3/XrV69atOn3rd5euX51zqk4pIjAzMwPYqugAzMysPJwUzMyslZOCmZm1clIwM7NWTgpmZtbKScHMzFo5KVipSFomaUwn62+Q9H/e5TaOltT0bl6jXpTcImmJpD8VHY91f04KtlGS5kpame2wK9MP89hWRPSNiNmdrP90RFydx7Yrsh3x5yQ9LWm5pCZJv5C0b7Z+gqTVkt7OpqclfVtS/6rXGC9p7Rb4zD4AfBgYHhGHtBNre9tZJmloDe+zyyRHq5+tiw7Auoy/ioj/KTIAST0iYm0dNnUdcBJwMTAF6AGcni17KitzTURcIakPsC9wDTBF0qERsTwr80hEfOBdxrIzMLfqNduzJbbTLklbR0RzHq9t5eSagr0r2ZHqFEnfk/QXSbMlHZ4tnydpgaQLqspPyJqA7suOsv8oaeeq9SFp16qy/yFpsqTlwDHZsn+uKn+qpCckvSXpJUnHZ8svlPRcto3Zkv62xvezG3ApcHZE3B8R70TEioj4WUT8a9vyEbEqIqYCpwCDgAs34zMcKmmSpMWSZkm6OFt+EXAzcFh29P/NzXjtuZK+LGmGpKWS7pDUR9J2wG+BodW1C0nfkHSnpP+U9BYwXlJvSd+XND+bvi+pd/b6R2c1qX+S9Ga2vXOzdQdLekPS1lXxfEzSE5v6Pqx+nBRsSzgUmEHaKf4XMBE4GNgVOA/4oaS+VeXPBa4GBgNPAD/r5LXPAb4F9AP+t3qFpEOAW4HLgAHAB4G52eoFwMnA9qQd9fckHVjDezkOaIqITWq/j4i3gfuAIzfl7zK3A03AUOAM4F8kHRcRPwY+TaoJ9I2Ir2/GawOcCRwPjAbGAuOzmscJwPzstftGxPys/KnAnaTP9GfA14D3A/sD+wGHAFdUvf57SN/lMOAC4CZJe2TJchGp+aviPOC2zXwfVgdOClaru7KaQGW6uGrdnIi4JWvauQMYAVyVHWX/DlhNShAVv4mIByPiHdIO5zBJIzrY7v+LiCkR0RIRq9qsuwj4SUTcl61/NSKeB4iI30TES5H8Efgdte2wBwGv1VCuPfOBgVXP39/mM3t/2z/I3vcHgMuzWscTpNrB+Zuw3bbbeanN+h9ExPyIWAz8N2nn3plHIuKu7DNdSUriV0XEgohYCHyznfj+T/Z9/xH4DSkRAfyUlAiQNBD4KOnAwUrKfQpWq9M66VN4o2p+JUBEtF1WXVOYV5mJiGWSFpOOkuexofaWVYwAJre3QtIJwNeB3UkHP9uyrj+gM4uA99ZQrj3DgMVVzx+toa1/KLA4q2lUvAyM24Ttbmw7r1fNr8i22Zm2n/nQLKaKl9u8xpI2fR7V6/8TeC6rKZ4JPBQRm5t0rQ5cU7AitNYKsp3FQNJRdns6G8Z3HrBL24VZe/cvgWuBnSJiACl5qIbYfg8Ml7QpO+XK+/gQ8NCm/B1Z7UJSv6plI4FXN/F1NkdHn23b5fNJHd4VI1n/+9oh66PYYH1EvAo8QuqoPx83HZWek4IV4URJH5DUi9S38FhEdFYj6MiPgQslHSdpK0nDJL0P6AX0BhYCzVmt4SO1vGBEvAj8CLg960TtlXXMniXpK23LZ52wBwF3AUuAWzblDWTv+2Hg29l2xpKaxTrrZ9lS3gAGqepU2g7cDlwhaYikwcCVpBpAtW9mn9WRpL6cX1StuxX4R9JZWr/eMqFbXpwUrFb/rfXPg383/9z/RWraWQwcRGqz3mRZZ/CFwPeApcAfgZ2zppjPAT8n7ajPASZtwkt/DvghcD3wF+Al0pHuf1eV+UdJb2fv4VZgOnD4Rk4d7cjZwCjS0fWvga9HxH2b8PeHacPrFA7e2B9l/S+3A7OzvoiOmpX+GZhGOpngKeDP2bKK10mf83xSMvt0pW8n82tSTePXm/n5WB3JN9mxepI0gXR2zxUbK2vlJ+lo4D8jYvhGyr0E/G3R17rYxrmmYGa5kvQxUj/F/UXHYhvns4/MLDeSHgD2As6PiJaCw7EauPnIzMxaufnIzMxadbnmo8GDB8eoUaOKDsPMrEuZPn36mxExZGPlulxSGDVqFNOmTSs6DDOzLkXSyxsv5eYjMzOr4qRgZmatnBTMzKxVl+tTaM+aNWtoampi1aq2Iyt3PX369GH48OH07Nmz6FDMrAF1i6TQ1NREv379GDVqFFItA2GWU0SwaNEimpqaGD16dNHhmFkDyq35SNJPlG7F+HQH6yXpB9ntB2fUeFesdq1atYpBgwZ16YQAIIlBgwZ1ixqPmXVNefYpTCDdArAjJwC7ZdMlwH+8m4119YRQ0V3eh5l1TbklhYh4kPXvQtXWqcCt2e0SHwUGSNrcO16ZmXVfb78NV14JU6fmvqkizz4axvq3/WvKlm1A0iWSpkmatnDhwroEl4e+fdfdkfKyyy5j77335rLLLiswIjPrEpYvh6uvhunTc99UkR3N7bWTtDs6X0TcBNwEMG7cuG4xgt+NN97IwoUL6d27d9GhmFk9RcCaNfDOO7BiBaxaleYr0+rVsGwZLF4MS5bA66+vqyH06pV7eEUmhSaq7tULDKfj+/R2CbfeeivXXnstkhg7dixXXXUV55xzDs3NzRx//LrulVNOOYXly5dz6KGH8tWvfpVPfOITBUZt1s2tXZt2vCtXpsfK/IoV6Qh85co0zZsH22yz/s65Mr90aXq+Zs26qe3zjS1bvXrdtCkkGDMGxo+HM87I5SOqVmRSmAR8VtJE4FBgaUS89q5f9QtfgCeeeNcvs57994fvf7/TIs888wzf+ta3mDJlCoMHD2bx4sWMHz+ez3zmM3zyk5/k+uuvby07adIk+vbtyxNbOk6zrqilBd54A157LbWdr1iRpsqOu7OpUqayw2+741+1Ku2Q343evWH77aFPH+jZM029eq2br0zbbtv+8sqy3r3TfGXq3Tv9TZ8+ab6yvndv2G47GDgQdtghPdaxRSG3pCDpduBoYLCkJtI9eXsCRMQNwGTgRGAWsIJ0r90u6/777+eMM85g8ODBAAwcOJApU6bwy1/+EoDzzz+fyy+/vMgQzcpj9Wr4znfgV7+CF15IzSUbs9VWaSfadtpmG+jfH3baKc336ZOmynxHy7bZBvr2XbessvOv3kFvvXU6Um8guSWFiDh7I+sDuHSLb3gjR/R5iYh2Tyf1KaZm7bj2WrjiCjjySLjwQthjDxg6NO3c2+7wK/O9ejXcDroI3eKK5jI47rjjOP300/niF7/IoEGDWLx4MUcccQQTJ07kvPPO42c/+1nRIZqVx/TpKRE8+GDRkVgbHhBvC9l777352te+xlFHHcV+++3Hl770Ja677jquv/56Dj74YJYuXVp0iGbl0dJS13Zyq51rClvQBRdcwAUXXLDeskceeaR1/itf+Urr/LJa2lDNuquWltRHYKXjb8XM6s9JobT8rZhZ/UW407ikuk1SSCczdX3d5X2Ydco1hdLqFt9Knz59WLRoUZffoVbup9CnT5+iQzHLl5NCaXWLjubhw4fT1NREVx4sr6Jy5zWzbs1JobS6RVLo2bOn71Rm1pVEOCmUlL8VM6s/1xRKy9+KmdVfS4vPPiopJwUzqz/XFErL34qZ1Z/7FErL34qZ1Z9rCqXlb8XM6s99CqXlpGBm9bd2LfToUXQU1g4nBTOrPyeF0nJSMLP6a252n0JJ+Vsxs/pqboZZs2DUqKIjsXY4KZhZff35z7B8ORx6aNGRWDucFMysfp56Ci6+GAYMgI98pOhorB3dYkA8MyuxN9+EP/wB7roLJk6E/v3htttgyJCiI7N2OCmY2Za1YAHcfTdMngyPPQZNTWn5wIHwd38H3/xmmrdSclIws023fDm88gq8/HLqNH7mGZg/H557Dl58MZUZPhw++EE48MDUf3DYYT4NtQtwUjBrdKtWpSaeJUtg8WJYtAgWLkzTkiWwdGlaXlm2YEFaXm3gQBg2DPbdFy64AE4+GcaO9VXLXZCTgll3t3IlzJ0Lr76amnJeeQVmzkxH9fPmpYTQke22S30AO+yQ+gDGjk2Pw4fDzjvDyJHpcfhwJ4BuwknBrLtYuzY13Tz+eJqmT4cZM9rf6Q8dmnbwhx6ajvB33DEd7Q8cmBLAjjvC4MHQu3f934cVyknBrCuKgCefTDv+xx9P5/4/+SSsWJHW9+qVmnJOOw1Gj047+113TfPDhkGfPsXGb6XlpGDWlTz/PPz4xzBhwroaQL9+sP/+8KlPwQEHpI7dPfeEnj0LDdW6JicFs7JbuRLuuANuvhmmTIGtt4aTToJjj00XgO2+u8cRsi3GScGszFauhGOOSef77747XHMNfPKTsNNORUdm3ZSTglmZXXddSggTJqRk4DN8LGe51jklHS9ppqRZkr7SzvqRkv4g6XFJMySdmGc8Zl3OhAmpmeiCC5wQrC5ySwqSegDXAycAewFnS9qrTbErgJ9HxAHAWcCP8orHrMtZtixdT3DssUVHYg0kz5rCIcCsiJgdEauBicCpbcoEsH023x+Yn2M8Zl3LO++kx379io3DGkqeSWEYMK/qeVO2rNo3gPMkNQGTgb9v74UkXSJpmqRpCxcuzCNWs/KJSI9uNrI6yjMptPdLjjbPzwYmRMRw4ETgNkkbxBQRN0XEuIgYN8TD7VqjcFKwAuSZFJqAEVXPh7Nh89BFwM8BIuIRoA8wOMeYzLqOlpb06GsQrI7y/LVNBXaTNFpSL1JH8qQ2ZV4BjgOQtCcpKbh9yAxcU7BC5JYUIqIZ+CxwL/Ac6SyjZyRdJemUrNg/ABdLehK4HRgfEW2bmMwak5OCFSDXi9ciYjKpA7l62ZVV888CR+QZg1mX5aRgBXBjpVlZOSlYAZwUzMrKScEK4KRgVlY++8gK4F+bWVm5pmAFcFIwKysnBSuAk4JZWTkpWAGcFMzKyknBCuCkYFZWlaTgjmarI//azMqqcvaRawpWR04KZmXl5iMrgJOCWVk5KVgBnBTMyspJwQrgpGBWVk4KVgAnBbOy8tlHVgD/2szKymcfWQGcFMzKys1HVgAnBbOyclKwAjgpmJWVk4IVwEnBrKycFKwATgpmZeWzj6wA/rWZlZXPPrICOCmYlZWbj6wATgpmZfXWW+lx++2LjcMaipOCWVktXpweBw4sNg5rKE4KZmX1/PPpcejQYuOwhuKkYFZGq1fDnXfCQQfBoEFFR2MNZOuiAzCzNhYtgr/+a3jySbjttqKjsQbjmoJZWSxaBN/9LowdC488ArfeCuedV3RU1mBcUzArypo18NRTcM89MHkyTJmSlh96KEyalJqOzOrMScGsXpYsgcceg3vvhdmz4aGH0jJICeDKK+GEE1JS8LUJVhAnBbMtac0aeOEFmDkznT30/PPw4oswaxa8+ea6ckOGwMknw4c/DMccA8OHFxezWZVck4Kk44HrgB7AzRHxr+2UORP4BhDAkxFxTp4xmW0xLS3pyP83v0mdwjNnphrA2rXryrznPbDnnqnjeNdd4cAD4eCDfUGalVZuSUFSD+B64MNAEzBV0qSIeLaqzG7AV4EjImKJpB3zisdssy1bBlOnpvb/OXNg7tw0zZqV1kHa8Y8dCx//OLzvfen57rt7529dTp41hUOAWRExG0DSROBU4NmqMhcD10fEEoCIWJBjPGa1mTNnXefv9Onw2mvr1m27LYweDaNGwRFHwPvfDx/9aGoOMusG8kwKw4B5Vc+bgEPblNkdQNIUUhPTNyLinrYvJOkS4BKAkSNH5hKsNbjXX4dbboGf/jQ1AwGMGZN2+LvtBvvvn6b3vtedwNat5ZkU2vvPiXa2vxtwNDAceEjSPhHxl/X+KOIm4CaAcePGtX0Ns8335pvw+c/DHXekvoAjj4RLL12XDJwArMHkmRSagBFVz4cD89sp82hErAHmSJpJShJTc4zLLJk+HT72sdQ89IUvwCWXpH4AswaW5xXNU4HdJI2W1As4C5jUpsxdwDEAkgaTmpNm5xiTWfLQQ6lPoKUlXTR27bVOCGbkWFOIiGZJnwXuJfUX/CQinpF0FTAtIiZl6z4i6VlgLXBZRCzKKyazVldemU4XnTrVncRmVXK9TiEiJgOT2yy7smo+gC9lk1l9LF0KDz4IX/2qE4JZGx4QzxrPzJmp2ejgg4uOxKx0nBSs8Sxdmh4HDy42DrMSclKwxtPSkh638s/frC3/V1jjiexSF1+DYLYBJwVrPE4KZh1yUrDG4+Yjsw75v8Iaj2sKZh3qNClI+rfs8eP1CcesDpwUzDq0sZrCiZJ6ku55YNY9OCmYdWhjVzTfA7wJbCfprarlIl2Q7DuIWNfjPgWzDnX6XxERl0VEf+A3EbF91dTPCcG6LNcUzDpU06FSRJyadyBmdeOkYNahTpuPJL3NhjfGaeXagnVJleYjJwWzDXSaFCKiH0A23PXrwG2k/oRzgX65R2eWB9cUzDpUa0/bRyPiRxHxdkS8FRH/AXwsz8DMclNJCu5oNttArf8VayWdK6mHpK0knUu6KY5Z1+OaglmHak0K5wBnAm9k08eBs/MKyixX7lMw61Ctd177JjA+IpYASBoIXAv8TV6BmeXGNQWzDtVaUxhbSQgAEbEYOCCfkMxy5j4Fsw7V+l+xlaQdKk+ymkKu93c2y42bj8w6VOuO/d+BhyXdSbpu4UzgW7lFZZYnNx+ZdaimpBARt0qaBhxLuk7hryPi2VwjM8uLk4JZh2puAsqSgBOBdX1OCmYdck+bNZ7m5vTYs2excZiVkJOCNZ7Vq9Njr17FxmFWQk4K1njeeSc9OimYbcBJwRqPawpmHXJSsMbjpGDWIScFazzvvJPOPOrRo+hIzErHScEaSwQ8+CCMHu1TUs3a4aEqrHE0N8O3vw0PPQQ/+lHR0ZiVkpOCdX8R8MAD8PnPw1NPwWmnwSWXFB2VWSnlmhQkHQ9cB/QAbo6If+2g3BnAL4CDI2JanjFZN9bSAq+9BnPmwKxZ8MgjMHs2vPIKvPACjBgBv/pVSgpuOjJrV25JQVIP4Hrgw0ATMFXSpLZjJknqB3wOeCyvWKybWboUZs5M0/PPw7PPpmnu3HVnFgH07w977gl77AGf/nSqHWy3XWFhm3UFedYUDgFmRcRsAEkTgVPZcPykq4FrgC/nGIt1NWvXpp18ZcdfnQTeeGNduR49YNddYd994dRTUwfymDHpcZddfIaR2SbKMykMA+ZVPW8CDq0uIOkAYERE3C2pw6Qg6RLgEoCRI0fmEKoVZtkyeOwxePppmDcPnnsOXnopNQFVH/UPGpSO+E86KT1WpjFjfL2B2RaUZ1Jor9E2WldKWwHfA8Zv7IUi4ibgJoBx48bFRopb2S1aBDfeCL/8JTz5ZKoVAPTuDe97H+yzTzrq32OP9HyPPVJSMLPc5ZkUmoARVc+HA/OrnvcD9gEeUOr0ew8wSdIp7mzuxiZNgvPOg7ffhiOPhH/6Jzj8cDjgANhxR3cAmxUsz6QwFdhN0mjgVeAs4JzKyohYCgyuPJf0APBlJ4RubPp0OP10OOgg+PGPUz+AmZVKbkkhIpolfRa4l3RK6k8i4hlJVwHTImJSXtu2krrttnQPg3vugYEDi47GzNqR63UKETEZmNxm2ZUdlD06z1isBJ54AsaNc0IwKzGPfWT1s2IFbL990VGYWSecFKx+VqyAbbctOgoz64STgtXPO+/4mgKzknNSsPryKadmpeakYGZmrZwUzMyslZOCmZm1clIwM7NWTgpmZtbKScHMzFo5KVj9hEc9Nys7JwWrL1+nYFZqTgpmZtbKScHMzFo5KZiZWSsnBTMza+WkYGZmrZwUzMyslZOC1c/q1bB1rneANbN3yUnB6mPNGliwAIYMKToSM+uED9ssfytXwtVXpzuvHX540dGYWSecFGzLaW5OtYF582DGDHj6aZg9Gx5+GBYvhrPPhr/6q6KjNLNOOClYbdauhVdfTTv5l15Kj/Pnw6JFKQm89lpKCNXjG/XtC6NHw4knwqc+BUcdVVz8ZlYTJwVbZ9mytMOfM2f9nf/s2TB3buoorth6a3jPe2DQIBg2DMaNg6FD4b3vTdPee8OYMbCVu63MuhInhUY3dy7ccgvcdx/86U+pRlDRvz/ssguMHQunn5528rvskh5HjPCZRGbdkP+rG9Xq1fDtb6dpzZp0pH/55bD//jBqVNr5DxxYdJRmVmdOCo1q/Hi4/Xb4xCfgmmtg5MiiIzKzEnBSaFQPPABnngkTJxYdiZmViHsBG9XatW4eMrMNOCk0qrVrfWaQmW3Ae4VG1dICPXoUHYWZlUyuSUHS8ZJmSpol6SvtrP+SpGclzZD0e0k75xmPVXFNwczakdteQVIP4HrgBGAv4GxJe7Up9jgwLiLGAncC1+QVj7XhmoKZtSPPQ8VDgFkRMTsiVgMTgVOrC0TEHyJiRfb0UWB4jvFYNdcUzKwdee4VhgHzqp43Zcs6chHw2/ZWSLpE0jRJ0xYuXLgFQ2xgrimYWTvyTApqZ1m0swxJ5wHjgO+0tz4iboqIcRExbojH498yXFMws3bkefFaEzCi6vlwYH7bQpI+BHwNOCoi3skxHqvmmoKZtSPPQ8WpwG6SRkvqBZwFTKouIOkA4EbglIhYkGMsVi0iJQXXFMysjdz2ChHRDHwWuBd4Dvh5RDwj6SpJp2TFvgP0BX4h6QlJkzp4OduSKiOhepRTM2sj171CREwGJrdZdmXV/Ify3L51YOXK9LjNNsXGYWal4/aDRvTqq+nRScHM2nD7QXfS3AxvvQVLl8LChem+yEuXpumNN9ItM+fMgf/5H+jdG449tuiIzaxknBS6grVr0069qSndD7n6sakJXn89rV+2rPPXGTQo3Srz0kvh4othzz3rE7+ZdRlOCmW0cGG6I9qf/pR2/vPnp1pAtT59YPjwNB1yCOy0EwwYkG6h2b8/DB6cpu23T8+HDEm1AzOzTjgplM2aNXDwwand/4gj4Kij0o5/xIj1HwcNArV3faCZ2eZzUiibBQvg5Zfhu9+FL36x6GjMrMH47KOyWbMmPQ4YUGwcZtaQnBTKptJ30LNnsXGYWUNyUiibSk3BVxubWQGcFMqmkhRcUzCzAjgplI2bj8ysQE4KZeOagpkVyEmhbCo1BfcpmFkBnBTKxjUFMyuQk0KZtLTA88+n+b59i43FzBqS2yjy1NKSBqmrjFRamZYsSSOYLloEb74Jr7ySxjh68UVYvjyNU7THHkVHb2YNyEnh3XjrLfjd7+DPf05DUi9evP60dGm69WVnBgyAoUNh1Cj44Adhv/3glFOgX7+6vAUzs2pOCptrzhz4wAfSCKYSjBmTRiUdMgR23z0NWFc9amll2n57GDgwTQMGuEPZzErFe6TNdd99KSH8+tdwwgkeltrMugV3NG+uyqmjhx/uhGBm3YaTwuby9QRm1g05KWwuX09gZt2Qk8Lmck3BzLohJ4XN5aRgZt2Qk8Lm8n0PzKwbclLYXM3N0KNHukbBzKyb8GFuLZqb4S9/WXel8qJF8NvfupPZzLqdxkkKLS1w223w9NNpfKGVK2H16nXTmjXrz69atS4RvPVW+6957rn1fQ9mZjlrnKRw990wfnyaHzwYttkmXXTWq1c64u/Va920zTZpuIp99103JMUOO6x73GGHdUNZmJl1I42TFF5+OT0uXJiSgpmZbaBxOppHjoTTTktH+WZm1q7GqSmcemqazMysQ7nWFCQdL2mmpFmSvtLO+t6S7sjWPyZpVJ7xmJlZ53JLCpJ6ANcDJwB7AWdL2qtNsYuAJRGxK/A94N/yisfMzDYuz5rCIcCsiJgdEauBiUDb9ptTgZ9m83cCx0m+GszMrCh5JoVhwLyq503ZsnbLREQzsBTY4DxPSZdImiZp2sKFC3MK18zM8kwK7R3xt71hcS1liIibImJcRIwbMmTIFgnOzMw2lGdSaAJGVD0fDszvqIykrYH+wOIcYzIzs07kmRSmArtJGi2pF3AWMKlNmUnABdn8GcD9EbFBTcHMzOojt+sUIqJZ0meBe4EewE8i4hlJVwHTImIS8GPgNkmzSDWEs/KKx8zMNk5d7cBc0kLg5c3888HAm1swnC3FcW0ax1W7MsYEjmtTbYm4do6IjXbKdrmk8G5ImhYR44qOoy3HtWkcV+3KGBM4rk1Vz7gaZ+wjMzPbKCcFMzNr1WhJ4aaiA+iA49o0jqt2ZYwJHNemqltcDdWnYGZmnWu0moKZmXXCScHMzFp1y6RQ1vs41BDXlyQ9K2mGpN9L2rkMcVWVO0NSSMr91LhaYpJ0ZvZ5PSPpv/KOqZa4JI2U9AdJj2ff44l1iusnkhZIerqD9ZL0gyzuGZIOLEFM52axzJD0sKT98o6plriqyh0saa2kM8oSl6SjJT2R/eb/mEsgEdGtJtLV0y8BY4BewJPAXm3K/B1wQzZ/FnBHSeI6Btg2m/9MWeLKyvUDHgQeBcYVHROwG/A4sEP2fMcyfFakDsHPZPN7AXPzjivb1geBA4GnO1h/IvBb0iCU7wceK0FMh1d9fyfUI6Za4qr6ru8HJgNnlCEuYADwLDAye57Lb7471hTKeh+HjcYVEX+IiBXZ00dJgwjmrZbPC+Bq4BpgVUliuhi4PiKWAETEgpLEFcD22Xx/NhwEMhcR8SCdDyZ5KnBrJI8CAyS9t8iYIuLhyvdH/X7vtXxWAH8P/BKox+8KqCmuc4BfRcQrWflcYuuOSWGL3cehgLiqXUQ6ssvbRuOSdAAwIiLurkM8NcUE7A7sLmmKpEclHV+SuL4BnCepiXSU+fd1iKsWm/r7q7d6/d43StIw4HTghqJjaWN3YAdJD0iaLumTeWwktwHxCrTF7uOwhdW8TUlomI8+AAAEDklEQVTnAeOAo3KNKNtcO8ta45K0FelWqePrEEvrZttZ1vaz2prUhHQ06QjzIUn7RMRfCo7rbGBCRPy7pMNIAz7uExEtOcZViyJ+8zWRdAwpKXyg6Fgy3wcuj4i1JbsR5NbAQcBxwDbAI5IejYgXtvRGuptNuY9DUx3v41BLXEj6EPA14KiIeCfnmGqJqx+wD/BA9g/yHmCSpFMiYlpBMVXKPBoRa4A5kmaSksTUnGKqNa6LgOMBIuIRSX1Ig5nVrRmiAzX9/upN0ljgZuCEiFhUdDyZccDE7Pc+GDhRUnNE3FVsWDQBb0bEcmC5pAeB/YAtmhRy7zyp90RKdLOB0azrDNy7TZlLWb+j+ecliesAUkfmbmX6vNqUf4D8O5pr+ayOB36azQ8mNY0MKkFcvwXGZ/N7kna8qtN3OYqOOylPYv2O5j+VIKaRwCzg8HrEUmtcbcpNoE4dzTV8XnsCv89+h9sCTwP7bOkYul1NIUp6H4ca4/oO0Bf4RXaU8kpEnFKCuOqqxpjuBT4i6VlgLXBZ5HykWWNc/wD8X0lfJDXPjI/sPzpPkm4nNaUNzvozvg70zOK+gdS/cSJpJ7wCuLAEMV1J6sv7UfZ7b446jARaQ1yF2FhcEfGcpHuAGUALcHNEdHpa7WbFUYffq5mZdRHd8ewjMzPbTE4KZmbWyknBzMxaOSmYmVkrJwUzM2vlpGC2iSSdJmmvouMwy4OTgtmmO400AuoGsivkzbosJwUz0nhTkv6UjVV/o6QekpZJ+pakJ7NB93aSdDhwCvCdrOwu2QBl/5KNb/95STsr3Q+jcl+Mkdk2Jki6QdJDkl6QdHK2/CFJ+1fFMiUb/sGs7pwUrOFJ2hP4BHBEROxPukL6XGA70vhK+5HuJXFxRDwMTCJdQb1/RLyUvcyAiDgqIv4d+CFpmOqxwM+AH1RtbhRpoMOTgBuysZFuJhtwUNLuQO+ImJHnezbriJOCWRp18iBgqqQnsudjgNVAZbjw6aQdekfuqJo/DKjcCe421h/98+cR0RIRL5LGUXof8AvgZEk9gb8hjbdjVgi3f5qlQeJ+GhFfXW+h9OWqcYvW0vn/y/JO1kUH8wARESsk3Ue6Ec6ZpFE6zQrhmoJZGnnyDEk7AkgaqM7vj/02aUjxjjzMukEWzwX+t2rdxyVtJWkXUm1kZrb8ZlIz09SIyHsYd7MOOSlYw4uIZ4ErgN9JmgHcB3R2q8qJwGWSHs927m19Drgwe63zgc9XrZsJ/JE0jPWnI2JVFsN04C3glnf7fszeDY+SalYnkiYAd0fEne2sG0q6V8X7ovi7tFkDc03BrGDZvXYfA77mhGBFc03BzMxauaZgZmatnBTMzKyVk4KZmbVyUjAzs1ZOCmZm1ur/Ayu7h0cHSLALAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(entropy_cnt.index, cumulative/cumulative[-1], 'r', label='cdf')\n",
    "plt.xlabel('entropy')\n",
    "plt.ylabel('cdf')\n",
    "plt.title('Empirical CDF of Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepr)",
   "language": "python",
   "name": "deepr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
