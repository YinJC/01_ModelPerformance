{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from pyro.infer.util import torch_item\n",
    "from torch.distributions.uniform import Uniform\n",
    "from torch.distributions.normal import Normal as Normal_torch\n",
    "\n",
    "# python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from scipy.misc import imread\n",
    "import math\n",
    "import pandas as pd\n",
    "\n",
    "# pyro\n",
    "import pyro\n",
    "from pyro.distributions import Normal, Categorical, MultivariateNormal\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam, SGD\n",
    "import pyro.poutine as poutine\n",
    "from pyro.contrib.autoguide import AutoDiagonalNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "resize = 32\n",
    "epoch = 20\n",
    "lr = 0.0001\n",
    "weight_decay = 0.0005\n",
    "num_samples = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((resize, resize)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize((resize, resize)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=True, download=True, transform=transform_train),batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('mnist-data/', train=False, transform=transform_test),batch_size=batch_size, shuffle=True)\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning_rate(init, epoch):\n",
    "    optim_factor = 0\n",
    "    if(epoch > 160):\n",
    "        optim_factor = 3\n",
    "    elif(epoch > 120):\n",
    "        optim_factor = 2\n",
    "    elif(epoch > 60):\n",
    "        optim_factor = 1\n",
    "\n",
    "    return init*math.pow(0.2, optim_factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self, num_classes, inputs=1):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inputs, 6, 5, stride=1, bias=False)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, stride=1, bias=False)\n",
    "        self.fc1 = nn.Linear(16*5*5, 120, bias=False)\n",
    "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
    "        self.fc3 = nn.Linear(84, num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.softplus(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(F.softplus(self.conv2(out)), 2)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = F.softplus(self.fc1(out))\n",
    "        out = F.softplus(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bayesian(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Bayesian, self).__init__()\n",
    "        self.net = LeNet(10, 1)\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "        \n",
    "    def normal_prior(self,name, params):\n",
    "        mu_param = pyro.param('{}_mu'.format(name), torch.randn_like(params))\n",
    "        sigma_param = F.softplus(pyro.param('{}_sigma'.format(name), torch.randn_like(params)))\n",
    "        prior = Normal(loc=mu_param, scale=sigma_param)\n",
    "        return prior\n",
    "    \n",
    "    def mean_field_norm_prior(self, name, params, eps=10e-7):\n",
    "        loc_init = pyro.param('{}_mu'.format(name), torch.normal(mean=torch.zeros_like(params), std=torch.mul(torch.ones_like(params), 0.1)))\n",
    "        untransformed_scale_init = pyro.param('{}_sigma'.format(name), torch.normal(mean=torch.ones_like(params)*(-3), std=torch.mul(torch.ones_like(params), 0.1)))\n",
    "        sigma = eps + F.softplus(untransformed_scale_init)\n",
    "        dist = Normal(loc=loc_init, scale=sigma)\n",
    "        return dist\n",
    "\n",
    "    def fixed_normal_prior(self, params):\n",
    "        dist = Normal(loc=torch.zeros_like(params), scale=torch.ones_like(params))\n",
    "        return dist\n",
    "    \n",
    "    def model(self, x, y):\n",
    "        conv1w_prior = self.fixed_normal_prior(self.net.conv1.weight)\n",
    "        conv2w_prior = self.fixed_normal_prior(self.net.conv2.weight)\n",
    "        fc1w_prior = self.fixed_normal_prior(self.net.fc1.weight)\n",
    "        fc2w_prior = self.fixed_normal_prior(self.net.fc2.weight)\n",
    "        fc3w_prior = self.fixed_normal_prior(self.net.fc3.weight)\n",
    "        \n",
    "        priors = {\n",
    "            'conv1.weight':conv1w_prior,\n",
    "            'conv2.weight':conv2w_prior, \n",
    "            'fc1.weight': fc1w_prior,\n",
    "            'fc2.weight':fc2w_prior,\n",
    "            'fc3.weight':fc3w_prior\n",
    "        }\n",
    "        \n",
    "        # lift module parameters to random variables sampled from the priors\n",
    "        lifted_module = pyro.random_module(\"module\", self.net, priors)\n",
    "        \n",
    "        # sample a classifier\n",
    "        lifted_reg_model = lifted_module()\n",
    "        \n",
    "        p_hat = self.log_softmax(lifted_reg_model(x))\n",
    "        \n",
    "        with pyro.plate('observe_data'):\n",
    "            pyro.sample(\"obs\", Categorical(logits=p_hat), obs=y)\n",
    "    \n",
    "    def guide(self, x, y):\n",
    "        conv1w_prior = self.mean_field_norm_prior('conv1w',self.net.conv1.weight)\n",
    "        conv2w_prior = self.mean_field_norm_prior('conv2w',self.net.conv2.weight)\n",
    "        fc1w_prior = self.mean_field_norm_prior('fc1w',self.net.fc1.weight)\n",
    "        fc2w_prior = self.mean_field_norm_prior('fc2w', self.net.fc2.weight)\n",
    "        fc3w_prior = self.mean_field_norm_prior('fc3w',self.net.fc3.weight)\n",
    "        \n",
    "        priors = {\n",
    "            'conv1.weight':conv1w_prior,\n",
    "            'conv2.weight':conv2w_prior, \n",
    "            'fc1.weight': fc1w_prior,\n",
    "            'fc2.weight':fc2w_prior,\n",
    "            'fc3.weight':fc3w_prior\n",
    "        }\n",
    "        lifted_module = pyro.random_module(\"module\", self.net, priors)\n",
    "        return lifted_module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bayesian(\n",
       "  (net): LeNet(\n",
       "    (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "    (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
       "    (fc1): Linear(in_features=400, out_features=120, bias=False)\n",
       "    (fc2): Linear(in_features=120, out_features=84, bias=False)\n",
       "    (fc3): Linear(in_features=84, out_features=10, bias=False)\n",
       "  )\n",
       "  (log_softmax): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Bayesian()\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_elbo_kl_annealing(model, guide, *args, **kwargs):\n",
    "    # get the annealing factor and latents to anneal from the keyword\n",
    "    # arguments passed to the model and guide\n",
    "    annealing_factor = kwargs.pop('annealing_factor', 1.0)\n",
    "    # run the guide and replay the model against the guide\n",
    "    guide_trace = poutine.trace(guide).get_trace(*args, **kwargs)\n",
    "    model_trace = poutine.trace(\n",
    "        poutine.replay(model, trace=guide_trace)).get_trace(*args, **kwargs)\n",
    "\n",
    "    elbo = 0.0\n",
    "    # loop through all the sample sites in the model and guide trace and\n",
    "    # construct the loss; note that we scale all the log probabilities of\n",
    "    # samples sites in `latents_to_anneal` by the factor `annealing_factor`\n",
    "    for name, site in model_trace.nodes.items():\n",
    "        if site[\"type\"] == \"sample\":\n",
    "            factor = annealing_factor if site[\"name\"].split('$$$')[0] in ['module'] else 1.0\n",
    "            elbo = elbo + factor * site[\"fn\"].log_prob(site[\"value\"]).sum()\n",
    "    for name, site in guide_trace.nodes.items():\n",
    "        if site[\"type\"] == \"sample\":\n",
    "            factor = annealing_factor if site[\"name\"].split('$$$')[0] in ['module'] else 1.0\n",
    "            elbo = elbo - factor * site[\"fn\"].log_prob(site[\"value\"]).sum()\n",
    "    return -elbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "optim = Adam({\"lr\": 0.01})\n",
    "svi = SVI(net.model, net.guide, optim, loss=simple_elbo_kl_annealing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, net):\n",
    "    sampled_models = net.guide(None, None)\n",
    "    yhats = sampled_models(x).data\n",
    "    return yhats\n",
    "\n",
    "def train(e, svi, loader):\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    m = math.ceil(len(loader.dataset)/batch_size)\n",
    "    svi.optim = Adam({\"lr\": learning_rate(lr, e), 'weight_decay': weight_decay})\n",
    "    \n",
    "    for batch_idx, data in enumerate(loader):\n",
    "        inputs_value = data[0]\n",
    "        targets = data[1]\n",
    "        \n",
    "        x = inputs_value.view(-1, 1, resize, resize).repeat(num_samples, 1, 1, 1).cuda()\n",
    "        y = targets.repeat(num_samples).cuda()\n",
    "        \n",
    "        beta = 2 ** (m - (batch_idx + 1)) / (2 ** m - 1)\n",
    "        \n",
    "        x, y = Variable(x), Variable(y)\n",
    "        \n",
    "        loss =svi.step(x, y, annealing_factor=beta)\n",
    "        train_loss += loss\n",
    "        \n",
    "        predicted = torch.argmax(predict(x, svi), dim=1)\n",
    "        correct += predicted.eq(y.data).cpu().sum().item()\n",
    "        total += targets.size(0)\n",
    "        \n",
    "#         print('|Epoch:{}/{}|Iter:{}/{}|Loss:{}|Acc:{}'.format(\n",
    "#             e, epoch, batch_idx+1, (len(loader.dataset.train_data)//batch_size)+1, loss, (100*correct/total)/num_samples))\n",
    "    print('================>Epoch: ',e, 'Loss: ', train_loss/(len(loader.dataset.train_data)*num_samples), 'Acc: ', (100*correct/total)/num_samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================>Epoch:  0 Loss:  2.0367423130289715 Acc:  36.66166666666667\n",
      "================>Epoch:  1 Loss:  0.8245115194574992 Acc:  81.86\n",
      "================>Epoch:  2 Loss:  0.5939065231974919 Acc:  89.50166666666667\n",
      "================>Epoch:  3 Loss:  0.4953631006717682 Acc:  92.71166666666667\n",
      "================>Epoch:  4 Loss:  0.4418179518679778 Acc:  94.495\n",
      "================>Epoch:  5 Loss:  0.40888828094681107 Acc:  95.40166666666667\n",
      "================>Epoch:  6 Loss:  0.3894409182097018 Acc:  96.06\n",
      "================>Epoch:  7 Loss:  0.3723757892141243 Acc:  96.42333333333333\n",
      "================>Epoch:  8 Loss:  0.3590844763955474 Acc:  96.78333333333333\n",
      "================>Epoch:  9 Loss:  0.3499815596949309 Acc:  97.12333333333333\n",
      "================>Epoch:  10 Loss:  0.3425780458386739 Acc:  97.285\n",
      "================>Epoch:  11 Loss:  0.3352619662763675 Acc:  97.575\n",
      "================>Epoch:  12 Loss:  0.3304026311603685 Acc:  97.71333333333334\n",
      "================>Epoch:  13 Loss:  0.3238934686621775 Acc:  97.80499999999999\n",
      "================>Epoch:  14 Loss:  0.32272454760681063 Acc:  97.90833333333333\n",
      "================>Epoch:  15 Loss:  0.31831025676521163 Acc:  98.06\n",
      "================>Epoch:  16 Loss:  0.3122788526607491 Acc:  98.15166666666667\n",
      "================>Epoch:  17 Loss:  0.30960560738132026 Acc:  98.24666666666667\n",
      "================>Epoch:  18 Loss:  0.3054341970763728 Acc:  98.19333333333333\n",
      "================>Epoch:  19 Loss:  0.3053741503309645 Acc:  98.26333333333334\n"
     ]
    }
   ],
   "source": [
    "for e in range(epoch):\n",
    "    train(e, svi, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T, net):\n",
    "    sampled_models = [net.guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = torch.stack(yhats, dim=1)\n",
    "    mean = torch.mean(yhats, 1)\n",
    "    return np.argmax(mean.cpu().numpy(), axis=1)\n",
    "\n",
    "def evaluate(T, loader, net):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted = predict(images.view(-1, 1, 32, 32).cuda(), T, net)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == np.array(labels)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T:  10 Acc:  99.0\n"
     ]
    }
   ],
   "source": [
    "acc = evaluate(10, test_loader, net)\n",
    "print('T: ', 10, 'Acc: ', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy remove samples with all probability less than 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T, net):\n",
    "    sampled_models = [net.guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = F.softmax(torch.stack(yhats, dim=1), dim=2)\n",
    "    mean = torch.mean(yhats, 1)\n",
    "    return np.argmax(mean.cpu().numpy(), axis=1), mean.cpu().numpy()\n",
    "\n",
    "def evaluate(T, loader, net, threshold=0.2):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_cnt = 0\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted, mean_prob = predict(images.view(-1, 1, 32, 32).cuda(), T, net)\n",
    "        confidence = np.max(mean_prob, axis=1)\n",
    "        idx = [idx for idx in range(confidence.shape[0]) if confidence[idx]>threshold]\n",
    "        all_cnt += len(labels)\n",
    "        total += len(idx)\n",
    "        correct += (predicted[idx] == np.array(labels)[idx]).sum().item()\n",
    "    return (100 * correct / total), all_cnt-total, total/all_cnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  99.17521625427479\n",
      "number of samples skipped : 58\n",
      "raio (able to predict/all sample): 0.9942\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio = evaluate(10, test_loader, net, threshold=0.5)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  99.2049914461105\n",
      "number of samples skipped : 63\n",
      "raio (able to predict/all sample): 0.9937\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio = evaluate(20, test_loader, net,threshold=0.5)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  99.45294296423867\n",
      "number of samples skipped : 129\n",
      "raio (able to predict/all sample): 0.9871\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio = evaluate(10, test_loader, net,threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  99.4630192502533\n",
      "number of samples skipped : 130\n",
      "raio (able to predict/all sample): 0.987\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio = evaluate(20, test_loader, net,threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T, net):\n",
    "    sampled_models = [net.guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = F.softmax(torch.stack(yhats, dim=1), dim=2)\n",
    "    mean = torch.mean(yhats, 1).cpu().numpy()\n",
    "    \n",
    "    # uncertainty\n",
    "    # yhats [batch * 10 * 10]\n",
    "    p_hat = yhats.cpu().numpy()\n",
    "    aleatoric = np.mean(p_hat*(1-p_hat), axis=1) # batch * 10\n",
    "    epistemic = np.mean(p_hat**2, axis=1) - np.mean(p_hat, axis=1)**2 # batch * 10\n",
    "    return np.argmax(mean, axis=1), mean, aleatoric, epistemic\n",
    "\n",
    "def evaluate(T, loader, net,threshold=0.2):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_cnt = 0\n",
    "    total_alea_thresh = 0\n",
    "    total_epis_thresh = 0\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted, mean_prob, aleatoric, epistemic = predict(images.view(-1, 1, 32, 32).cuda(), T, net)\n",
    "        confidence = np.max(mean_prob, axis=1)\n",
    "        idx = [idx for idx in range(confidence.shape[0]) if confidence[idx]>threshold]\n",
    "        all_cnt += len(labels)\n",
    "        total += len(idx)\n",
    "        correct += (predicted[idx] == np.array(labels)[idx]).sum().item()\n",
    "        \n",
    "        # uncertainty for the best choice\n",
    "        total_alea_thresh += np.choose(predicted, aleatoric.T)[idx].sum().item()\n",
    "        total_epis_thresh += np.choose(predicted, epistemic.T)[idx].sum().item()\n",
    "    return (100 * correct / total), all_cnt-total, total/all_cnt, total_alea_thresh/total, total_epis_thresh/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  99.16515791591229\n",
      "number of samples skipped : 58\n",
      "raio (able to predict/all sample): 0.9942\n",
      "mean epistemic: 0.004229519091317218\n",
      "mean aleaotoric: 0.009353471910526661\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio, mean_alea, mean_epis = evaluate(10, test_loader, net,threshold=0.5)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  99.21481779746325\n",
      "number of samples skipped : 66\n",
      "raio (able to predict/all sample): 0.9934\n",
      "mean epistemic: 0.004220060414655458\n",
      "mean aleaotoric: 0.009211155619507515\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio, mean_alea, mean_epis = evaluate(20, test_loader, net,threshold=0.5)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## threshold = 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  99.4224924012158\n",
      "number of samples skipped : 130\n",
      "raio (able to predict/all sample): 0.987\n",
      "mean epistemic: 0.0033791172226632377\n",
      "mean aleaotoric: 0.008370493447904408\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio, mean_alea, mean_epis = evaluate(10, test_loader, net,threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is:  99.45316455696202\n",
      "number of samples skipped : 125\n",
      "raio (able to predict/all sample): 0.9875\n",
      "mean epistemic: 0.003713118960585775\n",
      "mean aleaotoric: 0.008435791034864474\n"
     ]
    }
   ],
   "source": [
    "acc, skip, ratio, mean_alea, mean_epis = evaluate(20, test_loader, net,threshold=0.6)\n",
    "print('accuracy is: ', acc)\n",
    "print('number of samples skipped :', skip)\n",
    "print('raio (able to predict/all sample):', ratio)\n",
    "print('mean epistemic:', mean_epis)\n",
    "print('mean aleaotoric:', mean_alea)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analyse the sample with confidence over 0.6 but prediction is wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T, net):\n",
    "    sampled_models = [net.guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = F.softmax(torch.stack(yhats, dim=1), dim=2)\n",
    "    mean = torch.mean(yhats, 1).cpu().numpy()\n",
    "    \n",
    "    # uncertainty\n",
    "    # yhats [batch * 10 * 10]\n",
    "    p_hat = yhats.cpu().numpy()\n",
    "    aleatoric = np.mean(p_hat*(1-p_hat), axis=1) # batch * 10\n",
    "    epistemic = np.mean(p_hat**2, axis=1) - np.mean(p_hat, axis=1)**2 # batch * 10\n",
    "    return np.argmax(mean, axis=1), mean, aleatoric, epistemic\n",
    "\n",
    "def evaluate(T, loader, net, threshold=0.2):\n",
    "    cnt = 0\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted, mean_prob, aleatoric, epistemic = predict(images.view(-1, 1, 32, 32).cuda(), T, net)\n",
    "        confidence = np.max(mean_prob, axis=1)\n",
    "        idx = [idx for idx in range(confidence.shape[0]) if confidence[idx]>threshold]\n",
    "        correct = (predicted[idx] == np.array(labels)[idx])\n",
    "        wrong_idx = [i for i in range(len(correct)) if correct[i] == False]\n",
    "        usable_idx = np.array(idx)[wrong_idx]\n",
    "        if len(wrong_idx)>0:\n",
    "            cnt += 1\n",
    "            if cnt>1:\n",
    "                return images[usable_idx], labels[usable_idx], mean_prob[usable_idx], aleatoric[usable_idx], epistemic[usable_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label, prob, alea, epis = evaluate(10, test_loader, net, threshold=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confidence:\n",
      "[7.2027780e-03 1.6286856e-02 8.3926478e-03 2.5786329e-02 3.1992984e-03\n",
      " 1.5347804e-02 6.3475961e-04 7.5265104e-01 7.3810192e-03 1.6311747e-01]\n",
      "label:\n",
      "9\n",
      "prediction\n",
      "7\n",
      "alea \n",
      "[0.00710575 0.01567226 0.00820803 0.02437887 0.00317253 0.01486904\n",
      " 0.00063351 0.17424259 0.00725646 0.12619355]\n",
      "epis\n",
      "[4.51466985e-05 3.49340407e-04 1.14174924e-04 7.42525328e-04\n",
      " 1.65370111e-05 2.43206741e-04 8.46871671e-07 1.19249225e-02\n",
      " 7.00813398e-05 1.03166029e-02]\n"
     ]
    }
   ],
   "source": [
    "num = 0\n",
    "plt.figure()\n",
    "plt.imshow(image[num].numpy().squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "plt.close()\n",
    "print('confidence:')\n",
    "print(prob[num])\n",
    "print('label:')\n",
    "print(label[num].numpy())\n",
    "print('prediction')\n",
    "print(np.argmax(prob[num]))\n",
    "print('alea ')\n",
    "print(alea[num])\n",
    "print('epis')\n",
    "print(epis[num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Calibration Error (ECE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECELoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the Expected Calibration Error of a model.\n",
    "    (This isn't necessary for temperature scaling, just a cool metric).\n",
    "    The input to this loss is the logits of a model, NOT the softmax scores.\n",
    "    This divides the confidence outputs into equally-sized interval bins.\n",
    "    In each bin, we compute the confidence gap:\n",
    "    bin_gap = | avg_confidence_in_bin - accuracy_in_bin |\n",
    "    We then return a weighted average of the gaps, based on the number\n",
    "    of samples in each bin\n",
    "    See: Naeini, Mahdi Pakdaman, Gregory F. Cooper, and Milos Hauskrecht.\n",
    "    \"Obtaining Well Calibrated Probabilities Using Bayesian Binning.\" AAAI.\n",
    "    2015.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_bins=15):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ECELoss, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, softmaxes, labels):\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        ece = torch.zeros(1)\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                ece += torch.abs(avg_confidence_in_bin - accuracy_in_bin) * prop_in_bin\n",
    "\n",
    "        return ece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ece = ECELoss(n_bins = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T, net):\n",
    "    sampled_models = [net.guide(None, None) for _ in range(T)]\n",
    "    yhats = [F.softmax(model(x).data, dim=1) for model in sampled_models]\n",
    "    yhats = torch.stack(yhats, dim=1)\n",
    "    mean = torch.mean(yhats, 1)\n",
    "    return mean\n",
    "\n",
    "def evaluate(T, loader, net):\n",
    "    prob_list = []\n",
    "    label_list = []\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted = predict(images.view(-1, 1, 32, 32).cuda(), T, net)\n",
    "        label_list.extend(labels)\n",
    "        prob_list.append(predicted)\n",
    "    label_list = torch.stack(label_list, dim=0).view(-1).cpu()\n",
    "    prob_list = torch.cat(prob_list, dim=0).cpu()  \n",
    "    return ece.forward(prob_list, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ece_loss: 0.009982832707464695\n"
     ]
    }
   ],
   "source": [
    "ece_loss = evaluate(10, test_loader, net)\n",
    "print('ece_loss:', str(ece_loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reliability Diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReliabilityDiagram(nn.Module):\n",
    "    \"\"\"\n",
    "    Calculates the Expected Calibration Error of a model.\n",
    "    (This isn't necessary for temperature scaling, just a cool metric).\n",
    "    The input to this loss is the logits of a model, NOT the softmax scores.\n",
    "    This divides the confidence outputs into equally-sized interval bins.\n",
    "    In each bin, we compute the confidence gap:\n",
    "    bin_gap = | avg_confidence_in_bin - accuracy_in_bin |\n",
    "    We then return a weighted average of the gaps, based on the number\n",
    "    of samples in each bin\n",
    "    See: Naeini, Mahdi Pakdaman, Gregory F. Cooper, and Milos Hauskrecht.\n",
    "    \"Obtaining Well Calibrated Probabilities Using Bayesian Binning.\" AAAI.\n",
    "    2015.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_bins=10):\n",
    "        \"\"\"\n",
    "        n_bins (int): number of confidence interval bins\n",
    "        \"\"\"\n",
    "        super(ReliabilityDiagram, self).__init__()\n",
    "        bin_boundaries = torch.linspace(0, 1, n_bins + 1)\n",
    "        self.bin_lowers = bin_boundaries[:-1]\n",
    "        self.bin_uppers = bin_boundaries[1:]\n",
    "\n",
    "    def forward(self, softmaxes, labels):\n",
    "        confidences, predictions = torch.max(softmaxes, 1)\n",
    "        accuracies = predictions.eq(labels)\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        for bin_lower, bin_upper in zip(self.bin_lowers, self.bin_uppers):\n",
    "            # Calculated |confidence - accuracy| in each bin\n",
    "            in_bin = confidences.gt(bin_lower.item()) * confidences.le(bin_upper.item())\n",
    "            prop_in_bin = in_bin.float().mean()\n",
    "            if prop_in_bin.item() > 0:\n",
    "                accuracy_in_bin = accuracies[in_bin].float().mean()\n",
    "                avg_confidence_in_bin = confidences[in_bin].mean()\n",
    "                x.append(avg_confidence_in_bin)\n",
    "                y.append(accuracy_in_bin)\n",
    "        return torch.stack(x, dim=0).view(-1).cpu().numpy(), torch.stack(y, dim=0).view(-1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = ReliabilityDiagram(n_bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T, net):\n",
    "    sampled_models = [net.guide(None, None) for _ in range(T)]\n",
    "    yhats = [F.softmax(model(x).data, dim=1) for model in sampled_models]\n",
    "    yhats = torch.stack(yhats, dim=1)\n",
    "    mean = torch.mean(yhats, 1)\n",
    "    return mean\n",
    "\n",
    "def evaluate(T, loader, net):\n",
    "    prob_list = []\n",
    "    label_list = []\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted = predict(images.view(-1, 1, 32, 32).cuda(), T, net)\n",
    "        label_list.extend(labels)\n",
    "        prob_list.append(predicted)\n",
    "    label_list = torch.stack(label_list, dim=0).view(-1).cpu()\n",
    "    prob_list = torch.cat(prob_list, dim=0).cpu()  \n",
    "    return label_list, prob_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "label, prob = evaluate(10, test_loader, net)\n",
    "x,y = rd(prob, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.bar(x=x, height=y, width=0.05, label='output')\n",
    "plt.plot(np.linspace(0, 1, 11), np.linspace(0, 1, 11), 'r', '--')\n",
    "plt.xlabel('confidence')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Reliability Diagram')\n",
    "plt.xlim(0, 1)\n",
    "plt.ylim(0,1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What Model Don't Know"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST('fashion-mnist-data/', train=False, download=True, transform=transform_train\n",
    "                       ),\n",
    "        batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x, T, net):\n",
    "    sampled_models = [net.guide(None, None) for _ in range(T)]\n",
    "    yhats = [model(x).data for model in sampled_models]\n",
    "    yhats = F.softmax(torch.stack(yhats, dim=1), dim=2)\n",
    "    mean = torch.mean(yhats, 1).cpu().numpy()\n",
    "    \n",
    "    # uncertainty\n",
    "    # yhats [batch * 10 * 10]\n",
    "    p_hat = yhats.cpu().numpy()\n",
    "    aleatoric = np.mean(p_hat*(1-p_hat), axis=1) # batch * 10\n",
    "    epistemic = np.mean(p_hat**2, axis=1) - np.mean(p_hat, axis=1)**2 # batch * 10\n",
    "    return np.argmax(mean, axis=1), mean, aleatoric, epistemic\n",
    "\n",
    "def evaluate(T, loader, net,threshold=0.2):\n",
    "    entropy = 0\n",
    "    total = 0\n",
    "    all_cnt = 0\n",
    "    total_alea_thresh = 0\n",
    "    total_epis_thresh = 0\n",
    "    entropy = np.array([])\n",
    "    for j, data in enumerate(loader):\n",
    "        images, labels = data\n",
    "        predicted, mean_prob, aleatoric, epistemic = predict(images.view(-1, 1, 32, 32).cuda(), T, net)\n",
    "        confidence = np.max(mean_prob, axis=1)\n",
    "        idx = [idx for idx in range(confidence.shape[0]) if confidence[idx]>threshold]\n",
    "        all_cnt += len(labels)\n",
    "        total += len(idx)\n",
    "        entropy = np.concatenate([entropy, confidence])\n",
    "        # uncertainty for the best choice\n",
    "        total_alea_thresh += np.choose(predicted, aleatoric.T).sum().item()\n",
    "        total_epis_thresh += np.choose(predicted, epistemic.T).sum().item()\n",
    "    entropy = -np.log(entropy)\n",
    "    return all_cnt-total, total/all_cnt, total_alea_thresh/total, total_epis_thresh/total, entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sample skipped  4833\n",
      "predict ratio  0.5167\n",
      "mean alea  0.3465861307944831\n",
      "mean epis  0.0587088311343768\n"
     ]
    }
   ],
   "source": [
    "skip, ratio, alea_mean, epis_mean, entropy = evaluate(10, test_loader, net,threshold=0.5)\n",
    "print('number of sample skipped ', skip)\n",
    "print('predict ratio ',ratio)\n",
    "print('mean alea ', alea_mean)\n",
    "print('mean epis ', epis_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_cnt = pd.Series(entropy).value_counts().sort_index()\n",
    "cumulative = np.cumsum(entropy_cnt.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(entropy_cnt.index, cumulative/cumulative[-1], 'r', label='cdf')\n",
    "plt.xlabel('entropy')\n",
    "plt.ylabel('cdf')\n",
    "plt.title('Empirical CDF of Entropy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepr)",
   "language": "python",
   "name": "deepr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
